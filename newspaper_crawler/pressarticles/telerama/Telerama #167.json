{
    "description": "Le quotidien britannique \u201cThe Guardian\u201d a publi\u00e9 des dizaines de documents, internes \u00e0 Facebook, d\u00e9taillant la politique de mod\u00e9ration du r\u00e9seau social. Qui, par exemple, censure les appels au meurtre contre Donald Trump mais tol\u00e8re les photos de maltraitance infantile.",
    "author": "Pablo Maill\u00e9",
    "title": "\u201cFacebook Files\u201d : ce que nous r\u00e9v\u00e8lent les manuels de mod\u00e9ration de Facebook",
    "newspaper": "Telerama",
    "theme": "medias",
    "url": "http://www.telerama.fr/medias/facebook-files-ce-que-nous-revelent-les-manuels-de-moderation-de-facebook,158446.php",
    "date": "22/05/2017",
    "body": "Ignorer ou supprimer ? C\u2019est  l\u2019\u00e9ternel dilemme  qui se pose chaque jour aux mod\u00e9rateurs de Facebook. Face \u00e0 des photos de drapeaux nazis, des portraits d\u2019Oussama ben Laden ou des images d\u2019armes \u00e0 feu, que faire ? Les censurer, pour prot\u00e9ger les internautes les plus fragiles ou, au contraire, les laisser exister, au nom de la libert\u00e9 d\u2019expression ? Si le d\u00e9bat revient r\u00e9guli\u00e8rement sur le\u00a0devant\u00a0de la sc\u00e8ne, la position officielle du r\u00e9seau social paraissait jusqu\u2019alors assez floue, virant parfois \u00e0 l\u2019absurde. En 2011, par exemple, Facebook avait censur\u00e9  L\u2019Origine du monde , le c\u00e9l\u00e8bre tableau de nu f\u00e9minin de Gustave Courbet\u2026 mais se disait  r\u00e9ticent , quelques ann\u00e9es plus tard, \u00e0 supprimer des vid\u00e9os djihadistes. Les choses pourraient toutefois s\u2019\u00e9claircir : ce dimanche 21 mai, le quotidien britannique  The Guardian  a publi\u00e9 des dizaines de  documents , internes \u00e0 Facebook, qui d\u00e9taillent la politique de mod\u00e9ration du r\u00e9seau. Le m\u00e9dia s\u2019est procur\u00e9 pour la premi\u00e8re fois des extraits des  \u00ab manuels de mod\u00e9ration \u00bb \u00a0(jusqu\u2019alors r\u00e9serv\u00e9s \u00e0 ses mod\u00e9rateurs) et en a tir\u00e9 une s\u00e9rie de dix articles plus d\u00e9taill\u00e9s. Voici trois enseignements \u00e0 tirer de ces documents. Les appels au meurtre contre Donald Trump censur\u00e9s Vous n\u2019appr\u00e9ciez pas (mais alors, vraiment pas) Donald Trump ? Prenez garde : des publications comme  \u00ab Quelqu\u2019un devrait tirer sur Trump \u00bb  peuvent \u00eatre  supprim\u00e9s  par Facebook. La raison ? Donald Trump est un chef d\u2019Etat ; une menace le concernant repr\u00e9sente donc, d\u2019apr\u00e8s les r\u00e8gles du r\u00e9seau social, un  \u00ab risque cr\u00e9dible \u00bb , au m\u00eame titre que s\u2019il s\u2019agit de\u00a0n\u2019importe quel chef d\u2019Etat ,\u00a0 d\u2019un activiste ou d\u2019un journaliste (entre autres). De m\u00eame, si la menace concerne des sans-abris ou des \u00e9trangers en tant que groupe social, elle doit \u00eatre censur\u00e9e par les mod\u00e9rateurs du r\u00e9seau. En revanche, des menaces du type  \u00ab J\u2019esp\u00e8re que quelqu\u2019un te tuera \u00bb ,  \u00ab Quelqu\u2019un devrait battre un roux \u00bb  ou  \u00ab Allons frapper des gros \u00bb  sont prof\u00e9r\u00e9es \u00e0 l\u2019intention d\u2019utilisateurs \u00ab lambda \u00bb, ne faisant pas partie de la liste des  \u00ab groupes vuln\u00e9rables \u00bb  \u00e9tablie par Facebook. Elles sont donc tol\u00e9r\u00e9es, n\u2019\u00e9tant pas consid\u00e9r\u00e9es comme des\u00a0 \u00ab menaces cr\u00e9dibles \u00bb  mais seulement comme des expressions violentes. D\u00e9cryptage MacronLeaks : quand Facebook et Twitter tentent d'endiguer les fake news Les photos de maltraitance infantile tol\u00e9r\u00e9es D\u2019apr\u00e8s les documents, la violence\u00a0d\u2019une vid\u00e9o mise en ligne ne peut justifier \u00e0 elle seule sa censure. En clair, selon la  politique  du groupe de Mark Zuckerberg, certaines vid\u00e9os violentes peuvent aider \u00e0 des prises de conscience. Ainsi, dans le cas des vid\u00e9os concernant la\u00a0maltraitance des enfants, \u00a0 elles doivent \u00eatre indisponibles pour les mineurs (d\u00e9clar\u00e9s), et censur\u00e9es seulement dans le cas o\u00f9 elles sont partag\u00e9es avec  \u00ab sadisme et c\u00e9l\u00e9bration \u00bb . Celles qui montrent un enfant frapp\u00e9, br\u00fbl\u00e9 ou \u00e9trangl\u00e9 par un adulte sont pr\u00e9c\u00e9d\u00e9es d\u2019une mention sp\u00e9cifique. Les photos de maltraitance infantile, en revanche, sont syst\u00e9matiquement ignor\u00e9es. Selon Facebook, le but est de pouvoir venir en aide \u00e0 l\u2019enfant concern\u00e9, en maintenant en ligne des images qui permettent de l\u2019identifier. Le cas des tentatives de suicide en direct Au sujet des tentatives de suicide sur Facebook Live (l\u2019outil de diffusion en direct du r\u00e9seau social), r\u00e9currentes ces derniers mois, les  consignes  de l\u2019entreprise pr\u00e9cisent ne pas vouloir  \u00ab censurer ou punir davantage les personnes d\u00e9sesp\u00e9r\u00e9es qui tentent de se suicider \u00bb .  \u00ab Les experts ont \u00e9tabli qu\u2019il est pr\u00e9f\u00e9rable de laisser l\u2019utilisateur diffuser en direct tant qu\u2019il est en contact avec ses spectateurs \u00bb  pr\u00e9cise le document. Cependant, les mod\u00e9rateurs ont d\u00e9sormais pour consigne de  \u00ab supprimer toutes les vid\u00e9os d\u00e9peignant le suicide \u2013\u00a0sauf si elles ont une valeur informative \u2013 y compris quand ces vid\u00e9os sont partag\u00e9es par quelqu\u2019un d\u2019autre que la victime pour attirer l\u2019attention \u00bb  (la distinction entre un suicide \u00ab ayant \u00bb\u00a0une valeur informative et un suicide \u00ab d\u00e9pourvu \u00bb de valeur informative\u00a0n\u2019\u00e9tant pas pr\u00e9cis\u00e9e\u2026). Exemple de cas particulier, faisant exception : en octobre 2016, le r\u00e9seau social a choisi de laisser en ligne une vid\u00e9o montrant un citoyen \u00e9gyptien en train de s\u2019immoler par le feu pour protester contre la hausse incontr\u00f4l\u00e9e des prix dans son pays. R\u00e9cemment, Mark Zuckerberg a annonc\u00e9 que 3 000 mod\u00e9rateurs suppl\u00e9mentaires seraient  recrut\u00e9s  d\u2019ici l\u2019an prochain, en plus des 4 500 dont il dispose aujourd\u2019hui. Pour l\u2019heure, d\u2019apr\u00e8s  The Guardian , ceux-ci disposent en moyenne de seulement de 10 secondes pour d\u00e9cider si un contenu est acceptable ou non\u2026 Enqu\u00eate Le \u201cdigital labor\u201d, les nouveaux temps modernes   Abo \u00a0"
}